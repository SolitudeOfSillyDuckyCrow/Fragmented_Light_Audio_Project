# **üåä Proyecto Final: Fragmented Light Audio \- Ingenier√≠a de Datos**

## **üìÑ Resumen de Participaci√≥n (Abstract)**

Esta documentaci√≥n presenta la implementaci√≥n y validaci√≥n de una soluci√≥n integral de **Ingenier√≠a de Datos**, centrada en la transformaci√≥n y visualizaci√≥n de estructuras anal√≠ticas sobre una plataforma **Dockerizada** y orquestada por **Airflow**. El estudio tiene como prop√≥sito demostrar la capacidad de dise√±ar y ejecutar el ciclo completo **ELT (Extract, Load, Transform)** en un entorno reproducible y moderno.

Se inici√≥ con la definici√≥n de la infraestructura mediante docker-compose.yml, que levanta PostgreSQL, Apache Airflow y Grafana. La **Fase de Transformaci√≥n (T)** se orquesta con **Airflow** para aplicar **SQL Avanzado**, generando valor anal√≠tico en dos **Tablas de Reporte** estrat√©gicas. Espec√≠ficamente, se utilizan agregaciones (SUM, GROUP BY) y joins para el c√°lculo de m√©tricas de ventas y rendimiento de clientes.

El resultado final es un **pipeline ELT funcional** donde el esquema persistido contiene un total de **13 tablas** (11 originales m√°s 2 de reporte). El artefacto de entrega es un repositorio con c√≥digo 100% reproducible que valida el dominio en la **Orquestaci√≥n**, **Administraci√≥n de Bases de Datos** y **Visualizaci√≥n (BI)**.

## **üîë Palabras Clave**

**Ingenier√≠a de Datos**, **Docker Compose**, **PostgreSQL**, **Apache Airflow (DAGs)**, **Grafana**, **Arquitectura ELT**, **Transformaci√≥n SQL Avanzada**, **Tablas de Reporte**, **13 Tablas**, **Orquestaci√≥n de Pipelines**.

## **üöÄ Instrucciones de Despliegue y Uso**

| R√∫brica: Instrucciones de instalaci√≥n o uso |
| :---- |

El proyecto se despliega de forma local y reproducible usando Docker Compose.

1.  **Inicializaci√≥n de la Infraestructura:** Aseg√∫rese de tener Docker instalado y el archivo .env configurado. En la terminal, desde la carpeta ra√≠z, ejecute:  
   docker-compose up \-d

2.  **Paso 1: Carga del Esquema Base (Fase L):** Al iniciar Docker, el script **sql/01\_esquema\_base\_chinook.sql** se ejecuta autom√°ticamente en PostgreSQL.  
3.  **Paso 2: Transformaci√≥n (Fase T) con Airflow:** Orqueste la transformaci√≥n que crea las tablas de reporte (12 y 13).  
   * **Acceder a Airflow:** Navegue a http://localhost:8080.  
   * **Ejecutar DAG:** Active el DAG chinook\_elt\_pipeline y ejec√∫telo (Trigger DAG). El DAG ejecuta **sql/02\_transformacion\_reporting.sql**.  
   * **Verificaci√≥n:** El DAG finalizar√° con √©xito (verde), confirmando las 13 tablas.  
4.  **Paso 3: Visualizaci√≥n (Grafana):** Acceda a los datos transformados.  
   * **Acceder a Grafana:** Navegue a http://localhost:3000.  
   * **Creaci√≥n de Dashboards:** Utilice la fuente de datos **'Chinook PostgreSQL'** y las tablas de reporte (12 y 13\) para construir paneles anal√≠ticos.  
5.  **T√©cnica de Respaldo:** El archivo **sql/03\_dump\_final\_persistido.sql** contiene el *dump* completo del esquema final, cumpliendo con las t√©cnicas de respaldo.

## **‚úÖ Matriz de Cumplimiento T√©cnico**

| R√∫brica: Cumplimiento t√©cnico (Aplicar todos los temas del curso) |
| :---- |

| Tema del Curso | Evidencia en el Proyecto |
| :---- | :---- |
| **Administradores y manejadores de bases de datos** | Uso de **PostgreSQL** (en contenedor) y **Grafana** (para an√°lisis BI). |
| **Administraci√≥n de espacios l√≥gicos y f√≠sicos** | Gesti√≥n del esquema **public** con **13 tablas** y definici√≥n de PRIMARY KEY. |
| **Monitoreo y seguridad** | Variables de entorno (.env) segregadas y Airflow/Grafana protegidos con autenticaci√≥n. |
| **Afinaci√≥n de una base de datos** | Creaci√≥n de **Tablas de Reporte (Agregaci√≥n)** para optimizar consultas anal√≠ticas. |
| **Scripts y consultas funcionales** | Archivos **.sql** y el DAG de Python (orquestador) que son ejecutables a trav√©s de Airflow. |
| **Base de datos correctamente construida** | El esquema final contiene **13 tablas** y el pipeline ELT est√° orquestado por Airflow. |
